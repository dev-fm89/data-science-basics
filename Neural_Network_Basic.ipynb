{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c6777-232c-4e5a-a65d-ee23715f0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Neural Network Basics\n",
    "\n",
    "The human brain is the inspiration behind neural network architecture. Human brain cells, called neurons, form a complex, highly interconnected network and send electrical signals to each other to help humans process information. \n",
    "Similarly, an artificial neural network is made of artificial neurons that work together to solve a problem. Artificial neurons are software modules, called nodes, and artificial neural networks are software programs or algorithms that, \n",
    "at their core, use computing systems to solve mathematical calculations.\n",
    "\n",
    "A basic neural network has interconnected artificial neurons in three layers:\n",
    "\n",
    "- Input Layer\n",
    "Information from the outside world enters the artificial neural network from the input layer. \n",
    "Input nodes process the data, analyze or categorize it, and pass it on to the next layer.\n",
    "\n",
    "- Hidden Layer\n",
    "Hidden layers take their input from the input layer or other hidden layers. \n",
    "Artificial neural networks can have a large number of hidden layers. Each hidden layer analyzes the output from the previous layer, processes it further, and passes it on to the next layer.\n",
    "\n",
    "- Output Layer\n",
    "The output layer gives the final result of all the data processing by the artificial neural network. It can have single or multiple nodes. For instance, if we have a binary (yes/no) classification problem, the output layer will have one output node, which will give the result as 1 or 0. \n",
    "However, if we have a multi-class classification problem, the output layer might consist of more than one output node.\n",
    "\n",
    "Deep neural netwok\n",
    "Deep neural networks, or deep learning networks, have several hidden layers with millions of artificial neurons linked together. A number, called weight, represents the connections between one node and another. The weight is a positive number if one node excites another, or negative if one node suppresses the other. Nodes with higher weight values have more influence on the other nodes.\n",
    "Theoretically, deep neural networks can map any input type to any output type. However, they also need much more training as compared to other machine learning methods. They need millions of examples of training data rather than perhaps the hundreds or thousands that a simpler network might need.\n",
    "\n",
    "\n",
    "Types\n",
    "\n",
    "- Perceptron \n",
    "  Simplest - One input and one output layer. No hidden layer. \n",
    "\n",
    "- Shallow\n",
    "  one hidden layer\n",
    "\n",
    "- Deep \n",
    "  multiple hidden layers       \n",
    "\n",
    "- Feedforward neural networks\n",
    "  Feedforward neural networks process data in one direction, from the input node to the output node. \n",
    "  Every node in one layer is connected to every node in the next layer. A feedforward network uses a feedback process to improve predictions over time.\n",
    "\n",
    "- Convolutional neural networks\n",
    "  They have three main types of layers, which are:\n",
    "  - Convolutional layer\n",
    "  - Pooling layer\n",
    "  - Fully-connected (FC) layer\n",
    "\n",
    "    Image processing\n",
    "    Computer Vision\n",
    "    Speech Recognition\n",
    "    Machine translation\n",
    "\n",
    "    AlexNet \n",
    "    VGGNet  \n",
    "    GoogLeNet \n",
    "    ResNet \n",
    "    ZFNet\n",
    "\n",
    "- Recurrent\n",
    "  Designed to save the output of a layer, Recurrent Neural Network is fed back to the input to help in predicting the outcome of the layer.\n",
    "  LSTM is improvment of this kind of network\n",
    "  Text processing like auto suggest, grammar checks, etc.\n",
    "  Text to speech processing\n",
    "  Image tagger\n",
    "  Sentiment Analysis\n",
    "  Translation\n",
    "\n",
    "- Modular \n",
    "  A modular neural network has a number of different networks that function independently and perform sub-tasks. \n",
    "  Stock market prediction systems\n",
    "\n",
    "- Radial Basis Function Neural Networks (RBF)\n",
    "\n",
    "- Transformer neural network \n",
    "   LLMs & generative AI\n",
    "\n",
    "\n",
    "How a neural network work in general :\n",
    "\n",
    "Each neuron receives a multiplied version of inputs and random weights, which is then added with a static bias value (unique to each neuron layer); \n",
    "this is then passed to an appropriate activation function which decides the final value to be given out of the neuron. \n",
    "There are various activation functions available as per the nature of input values. \n",
    "Once the output is generated from the final neural net layer, loss function (input vs output)is calculated, \n",
    "and backpropagation is performed where the weights are adjusted to make the loss minimum. \n",
    "Finding optimal values of weights is what the overall operation focuses around.\n",
    "- Activation Function is a mathematical formula that helps the neuron to switch ON/OFF.\n",
    "- Backpropagation is key algo to set the weights and biases\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
